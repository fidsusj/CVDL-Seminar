\section{Introduction} \label{introduction}
% Problem statement, motivation, main idea

VGG\footnote{Visual Geometry Group, Department of Engineering Science, University of Oxford} \cite{KarenSimonyan.2014}, Inception \cite{ChristianSzegedy.2014}, ResNet \cite{KaimingHe.2015}, DenseNet \cite{GaoHuang.2016}, Xception \cite{FrancoisChollet.2017}, ResNeXt \cite{SainingXie.2017}, EfficientNet \cite{LeMingxingTan.2019}, RegNet \cite{IlijaRadosavovic.2020}, the history of research in convolutional neural networks (CNNs) is an ancient discipline in computer vision. Over the years such CNNs became more and more accurate and efficient, but also more complicated to implement and to understand as many architecture-specific ideas and components got introduced. Such architectures do not even need to be manually designed anymore as neural architecture search (NAS) methods give the opportunity to learn optimal architectural designs right away. Old VGG-style plain CNNs containing only 3x3 convolutional, pooling and ReLU activation layers seem to be almost completely out-of-date. 

Besides all the benefits of enabling the training of deeper and more accurate models such architectures also have a few downsides. Multi-branch models are not only difficult to implement and to customize, they also do not manage to achieve a decent speed-accuracy trade-off anymore as the multi-branch architectures introduce high memory access costs (MACs) by branch additions/concatenations, depthwise separable convolutions or channel shuffling (see \autoref{related_work}). A further factor for reduced inference speed are the synchronization overheads through the many distinct architectural components (especially in NAS-created models) which make parallelism more difficult. Plain VGG-style models do not own such inherent speed bottlenecks and high memory costs, also they are not bound to certain constraints like shape matching needed for branch additions and are also more friendly to channel pruning \cite{HaoLi.2017} which removes low-impact filters. On the other hand, plain VGG-style models are difficult to train to decent depths because of vanishing gradient problems. They also cannot be used as an implicit ensemble of multiple shallower models as ResNet-like architectures can. 

RepVGG therefore introduces a re-parameterization method that helps to transform parameters of a ResNet-like training-time architecture to a VGG-like inference-time architecture using simple linear algebra. The resulting model can thus be trained until reasonable accuracy by the increased depth and an implicit ensemble-like setup during training and still achieves far higher speed during inference compared to current multi-branch models. The few types of operators needed for the VGG-like inference-time architecture and its single branch character also help to integrate more computing units onto the chip, which can furthermore individually be optimized on hardware-level giving additional speed gains. Having a plain feed-forward architecture during inference also makes the final model more memory-efficient in the end. 

The goal of RepVGG is it therefore to provide a simple and efficient VGG-style plain CNN during inference obtained by applying a structural re-parameterization onto a trained ResNet-like multi-branch model. RepVGG will be evaluated both for image classification on ImageNet \cite{JiaDeng.2009} as well as for semantic segmentation on Cityscapes \cite{MariusCordts.2016}. 

Before the re-parameterization method and architecture of RepVGG will be introduced, an extensive examination of the fundamentals and related work will be given. Many of the models introduced in this section will be important for major arguments, comparisons and the context of later parts of this paper. 